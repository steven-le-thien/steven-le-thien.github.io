[{"content":"Foreword This post, and subsequent posts, aim to be self-content while carrying a narrative that builds up over time. As I walk the fine line between being rigorous and keeping things intuitive, I really appreciate any constructive feedback as to how I can improve my writings (one of the main reasons I started this blog!) so that we all enjoy this process and learn a thing or two.\nClassification tasks We describe a simple binary classification problem that takes a training dataset $\\mathcal{D} = { (x_i, y_i) } _{i \\in [n]}$ with $n$ training examples\nDeep nets trained to perform classification tasks intuitively depend on the loss function to form representations that groups training examples\n","date":"2021-11-20T00:00:00Z","permalink":"https://steven-le-thien.github.io/p/training-invariances-in-deep-nets-and-its-consequences-i-linear-networks/","title":"Training invariances in deep nets and its consequences I: Linear networks"}]